{"forget-set": {"overall-regurgitation-score": 0.6099407354248476, "overall-knowledge-score": 0.9689119170984456, "Task1": {"regurgitation-score": 0.6018275408976567, "knowledge-score": 0.9029126213592233}, "Task2": {"regurgitation-score": 0.8220060927969706, "knowledge-score": 0.9823529411764705}, "Task3": {"regurgitation-score": 0.47915452526349084, "knowledge-score": 0.9685534591194969}}, "retain-set": {"overall-regurgitation-score": 0.6099407354248476, "overall-knowledge-score": 0.9689119170984456, "Task1": {"regurgitation-score": 0.6018275408976567, "knowledge-score": 0.9029126213592233}, "Task2": {"regurgitation-score": 0.8220060927969706, "knowledge-score": 0.9823529411764705}, "Task3": {"regurgitation-score": 0.47915452526349084, "knowledge-score": 0.9685534591194969}}, "mia_loss_acc": 1.0, "aggregated-terms": [0.39817245910234333, 0.09708737864077666, 0.17799390720302943, 0.01764705882352946, 0.5208454747365092, 0.03144654088050314, 0.6018275408976567, 0.9029126213592233, 0.8220060927969706, 0.9823529411764705, 0.47915452526349084, 0.9685534591194969], "harmonic-mean-task-aggregate": 0.10261727430670013, "aggregate-score": -1}