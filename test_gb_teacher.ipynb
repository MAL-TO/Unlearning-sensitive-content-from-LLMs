{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ebayat/Unlearning-sensitive-content-from-LLMs/.conda/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "from good_bad_teacher import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_run():\n",
    "    import torch\n",
    "    import logging\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "    logger = logging.getLogger(__name__)\n",
    "    \n",
    "    try:\n",
    "        # Initialize configuration\n",
    "        logger.info(\"Initializing configuration...\")\n",
    "        config_manager = ConfigManager()\n",
    "        config = config_manager.config\n",
    "        \n",
    "        # Initialize model manager\n",
    "        logger.info(\"Initializing model manager...\")\n",
    "        model_manager = ModelManager(config)\n",
    "        \n",
    "        # Try loading just one model first as a test\n",
    "        logger.info(\"Testing model loading...\")\n",
    "        test_model = model_manager._load_model()\n",
    "        logger.info(\"Successfully loaded test model\")\n",
    "        \n",
    "        # If the test model loaded successfully, proceed with the rest\n",
    "        logger.info(\"Initializing data manager...\")\n",
    "        data_manager = DataManager(config)\n",
    "        \n",
    "        # Load and prepare data\n",
    "        logger.info(\"Loading data...\")\n",
    "        retain_train_loader, forget_train_loader, retain_val_loader, forget_val_loader = data_manager.create_dataloaders(batch_size=8)\n",
    "        \n",
    "        logger.info(\"Data loading completed successfully!\")\n",
    "        \n",
    "        # Initialize all models\n",
    "        logger.info(\"Initializing all models...\")\n",
    "        good_teacher, bad_teacher = model_manager.initialize_teachers()\n",
    "        student = model_manager.initialize_student()\n",
    "        \n",
    "        logger.info(\"Models initialized successfully!\")\n",
    "        \n",
    "        logger.info(\"Test completed successfully!\")\n",
    "        \n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error occurred: {str(e)}\")\n",
    "        logger.error(f\"Error type: {type(e)}\")\n",
    "        import traceback\n",
    "        logger.error(f\"Traceback: {traceback.format_exc()}\")\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Initializing configuration...\n",
      "INFO:__main__:Initializing model manager...\n",
      "INFO:__main__:Testing model loading...\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  4.91it/s]\n",
      "INFO:__main__:Successfully loaded test model\n",
      "INFO:__main__:Initializing data manager...\n",
      "INFO:__main__:Loading data...\n",
      "INFO:__main__:Data loading completed successfully!\n",
      "INFO:__main__:Initializing all models...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing good teacher...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  4.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing bad teacher...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:accelerate.utils.modeling:We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing student...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  4.90it/s]\n",
      "INFO:__main__:Models initialized successfully!\n",
      "INFO:__main__:Test completed successfully!\n"
     ]
    }
   ],
   "source": [
    "test_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Initializing test components...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing good teacher...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  4.83it/s]\n",
      "INFO:accelerate.utils.modeling:We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing bad teacher...\n",
      "Initializing student...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  4.91it/s]\n",
      "INFO:__main__:Using device: cuda\n",
      "INFO:__main__:\n",
      "STEP 1: Testing forward pass...\n",
      "INFO:__main__:\n",
      "Good Teacher forward pass results:\n",
      "INFO:__main__:Output keys: odict_keys(['loss', 'logits', 'past_key_values'])\n",
      "INFO:__main__:Logits shape: torch.Size([2, 512, 50304])\n",
      "INFO:__main__:Loss value: 20.0908\n",
      "INFO:__main__:\n",
      "Bad Teacher forward pass results:\n",
      "INFO:__main__:Output keys: odict_keys(['loss', 'logits', 'past_key_values'])\n",
      "INFO:__main__:Logits shape: torch.Size([2, 512, 50304])\n",
      "INFO:__main__:Loss value: 16.7031\n",
      "INFO:__main__:\n",
      "Student forward pass results:\n",
      "INFO:__main__:Output keys: odict_keys(['loss', 'logits', 'past_key_values'])\n",
      "INFO:__main__:Logits shape: torch.Size([2, 512, 50304])\n",
      "INFO:__main__:Loss value: 20.0908\n",
      "INFO:__main__:✓ Forward passes completed successfully\n",
      "INFO:__main__:\n",
      "STEP 2: Testing training step...\n",
      "INFO:__main__:\n",
      "Testing retain step:\n",
      "INFO:__main__:Initial loss: 22.4500\n",
      "INFO:__main__:Final loss: 21.8480\n",
      "INFO:__main__:Loss change: 0.6020\n",
      "INFO:__main__:\n",
      "Testing forget step:\n",
      "INFO:__main__:Initial loss: 21.8350\n",
      "INFO:__main__:Final loss: 23.3594\n",
      "INFO:__main__:Loss change: -1.5245\n",
      "INFO:__main__:✓ Training steps completed successfully\n",
      "INFO:__main__:\n",
      "🎉 All tests completed successfully!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✨ Final Result:\n",
      "🎉 All tests passed successfully!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import logging\n",
    "import traceback\n",
    "from good_bad_teacher import (\n",
    "    ConfigManager, \n",
    "    DataManager, \n",
    "    ModelManager,\n",
    "    TeacherStudentUnlearning\n",
    ")\n",
    "\n",
    "def test_model_steps():\n",
    "    \"\"\"\n",
    "    Test single forward pass and training step for the Good-Bad Teacher implementation.\n",
    "    \"\"\"\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format='%(asctime)s - %(levelname)s - %(message)s'\n",
    "    )\n",
    "    logger = logging.getLogger(__name__)\n",
    "\n",
    "    try:\n",
    "        # Initialize components\n",
    "        logger.info(\"Initializing test components...\")\n",
    "        config_manager = ConfigManager()\n",
    "        config = config_manager.config\n",
    "        data_manager = DataManager(config)\n",
    "        model_manager = ModelManager(config)\n",
    "\n",
    "        # Get dataloaders\n",
    "        retain_loader, forget_loader, _, _ = data_manager.create_dataloaders(batch_size=2)\n",
    "        \n",
    "        # Initialize models\n",
    "        good_teacher, bad_teacher = model_manager.initialize_teachers()\n",
    "        student = model_manager.initialize_student()\n",
    "        \n",
    "        # Set up device\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        logger.info(f\"Using device: {device}\")\n",
    "        \n",
    "        #######################\n",
    "        # 1. Test Forward Pass\n",
    "        #######################\n",
    "        logger.info(\"\\nSTEP 1: Testing forward pass...\")\n",
    "        try:\n",
    "            # Move models to device\n",
    "            good_teacher = good_teacher.to(device)\n",
    "            bad_teacher = bad_teacher.to(device)\n",
    "            student = student.to(device)\n",
    "            \n",
    "            # Set models to eval mode\n",
    "            good_teacher.eval()\n",
    "            bad_teacher.eval()\n",
    "            student.eval()\n",
    "            \n",
    "            # Get a batch\n",
    "            batch = next(iter(retain_loader))\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            \n",
    "            # Test forward pass for each model\n",
    "            with torch.no_grad():\n",
    "                # Good teacher forward pass\n",
    "                good_teacher_output = good_teacher(**batch)\n",
    "                logger.info(\"\\nGood Teacher forward pass results:\")\n",
    "                logger.info(f\"Output keys: {good_teacher_output.keys()}\")\n",
    "                logger.info(f\"Logits shape: {good_teacher_output.logits.shape}\")\n",
    "                logger.info(f\"Loss value: {good_teacher_output.loss.item():.4f}\")\n",
    "                \n",
    "                # Bad teacher forward pass\n",
    "                bad_teacher_output = bad_teacher(**batch)\n",
    "                logger.info(\"\\nBad Teacher forward pass results:\")\n",
    "                logger.info(f\"Output keys: {bad_teacher_output.keys()}\")\n",
    "                logger.info(f\"Logits shape: {bad_teacher_output.logits.shape}\")\n",
    "                logger.info(f\"Loss value: {bad_teacher_output.loss.item():.4f}\")\n",
    "                \n",
    "                # Student forward pass\n",
    "                student_output = student(**batch)\n",
    "                logger.info(\"\\nStudent forward pass results:\")\n",
    "                logger.info(f\"Output keys: {student_output.keys()}\")\n",
    "                logger.info(f\"Logits shape: {student_output.logits.shape}\")\n",
    "                logger.info(f\"Loss value: {student_output.loss.item():.4f}\")\n",
    "            \n",
    "            logger.info(\"✓ Forward passes completed successfully\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            logger.error(\"✗ Error in forward pass testing:\")\n",
    "            logger.error(traceback.format_exc())\n",
    "            raise\n",
    "\n",
    "        #######################\n",
    "        # 2. Test Training Step\n",
    "        #######################\n",
    "        logger.info(\"\\nSTEP 2: Testing training step...\")\n",
    "        try:\n",
    "            # Initialize unlearning system\n",
    "            unlearning_system = TeacherStudentUnlearning(\n",
    "                good_teacher=good_teacher,\n",
    "                bad_teacher=bad_teacher,\n",
    "                student=student,\n",
    "                config=config\n",
    "            )\n",
    "            \n",
    "            # Set student to training mode\n",
    "            student.train()\n",
    "            \n",
    "            # Keep teachers in eval mode\n",
    "            good_teacher.eval()\n",
    "            bad_teacher.eval()\n",
    "            \n",
    "            # Initialize optimizer\n",
    "            optimizer = torch.optim.Adam(\n",
    "                student.parameters(),\n",
    "                lr=config['training']['learning_rate']\n",
    "            )\n",
    "            \n",
    "            # Test retain step\n",
    "            logger.info(\"\\nTesting retain step:\")\n",
    "            batch = next(iter(retain_loader))\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            \n",
    "            # Record initial loss\n",
    "            with torch.no_grad():\n",
    "                initial_output = student(**batch)\n",
    "                initial_loss = initial_output.loss.item()\n",
    "            \n",
    "            # Perform optimization step\n",
    "            optimizer.zero_grad()\n",
    "            retain_loss = unlearning_system.calculate_retain_loss(\n",
    "                student(**batch).logits,\n",
    "                good_teacher(**batch).logits,\n",
    "                batch\n",
    "            )\n",
    "            retain_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Record final loss\n",
    "            with torch.no_grad():\n",
    "                final_output = student(**batch)\n",
    "                final_loss = final_output.loss.item()\n",
    "            \n",
    "            logger.info(f\"Initial loss: {initial_loss:.4f}\")\n",
    "            logger.info(f\"Final loss: {final_loss:.4f}\")\n",
    "            logger.info(f\"Loss change: {initial_loss - final_loss:.4f}\")\n",
    "            \n",
    "            # Test forget step\n",
    "            logger.info(\"\\nTesting forget step:\")\n",
    "            batch = next(iter(forget_loader))\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            \n",
    "            # Record initial loss\n",
    "            with torch.no_grad():\n",
    "                initial_output = student(**batch)\n",
    "                initial_loss = initial_output.loss.item()\n",
    "            \n",
    "            # Perform optimization step\n",
    "            optimizer.zero_grad()\n",
    "            forget_loss = unlearning_system.calculate_forget_loss(\n",
    "                student(**batch).logits,\n",
    "                bad_teacher(**batch).logits,\n",
    "                batch\n",
    "            )\n",
    "            forget_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Record final loss\n",
    "            with torch.no_grad():\n",
    "                final_output = student(**batch)\n",
    "                final_loss = final_output.loss.item()\n",
    "            \n",
    "            logger.info(f\"Initial loss: {initial_loss:.4f}\")\n",
    "            logger.info(f\"Final loss: {final_loss:.4f}\")\n",
    "            logger.info(f\"Loss change: {initial_loss - final_loss:.4f}\")\n",
    "            \n",
    "            logger.info(\"✓ Training steps completed successfully\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(\"✗ Error in training step testing:\")\n",
    "            logger.error(traceback.format_exc())\n",
    "            raise\n",
    "\n",
    "        logger.info(\"\\n🎉 All tests completed successfully!\")\n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(\"\\n❌ Testing failed with error:\")\n",
    "        logger.error(traceback.format_exc())\n",
    "        return False\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    success = test_model_steps()\n",
    "    print(\"\\n✨ Final Result:\")\n",
    "    print(\"🎉 All tests passed successfully!\" if success else \"❌ Tests failed. Check the logs above for details.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 12.75it/s]\n"
     ]
    }
   ],
   "source": [
    "config = ConfigManager()\n",
    "m = config.config['model']['good_teacher']['path']\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing direct tokenizer load from: /data1/malto/unlearning_llm/models/semeval25-unlearning-model-1B-model\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Can't load tokenizer for '/data1/malto/unlearning_llm/models/semeval25-unlearning-model-1B-model'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/data1/malto/unlearning_llm/models/semeval25-unlearning-model-1B-model' is the correct path to a directory containing all relevant files for a GPTNeoXTokenizerFast tokenizer.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m test_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/data1/malto/unlearning_llm/models/semeval25-unlearning-model-1B-model\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTesting direct tokenizer load from:\u001b[39m\u001b[38;5;124m\"\u001b[39m, test_path)\n\u001b[0;32m----> 6\u001b[0m test_tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mAutoTokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Unlearning-sensitive-content-from-LLMs/.conda/lib/python3.11/site-packages/transformers/models/auto/tokenization_auto.py:939\u001b[0m, in \u001b[0;36mAutoTokenizer.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    936\u001b[0m tokenizer_class_py, tokenizer_class_fast \u001b[38;5;241m=\u001b[39m TOKENIZER_MAPPING[\u001b[38;5;28mtype\u001b[39m(config)]\n\u001b[1;32m    938\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tokenizer_class_fast \u001b[38;5;129;01mand\u001b[39;00m (use_fast \u001b[38;5;129;01mor\u001b[39;00m tokenizer_class_py \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 939\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtokenizer_class_fast\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    940\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    941\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tokenizer_class_py \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Unlearning-sensitive-content-from-LLMs/.conda/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2197\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, trust_remote_code, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   2194\u001b[0m \u001b[38;5;66;03m# If one passes a GGUF file path to `gguf_file` there is no need for this check as the tokenizer will be\u001b[39;00m\n\u001b[1;32m   2195\u001b[0m \u001b[38;5;66;03m# loaded directly from the GGUF file.\u001b[39;00m\n\u001b[1;32m   2196\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(full_file_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m full_file_name \u001b[38;5;129;01min\u001b[39;00m resolved_vocab_files\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m gguf_file:\n\u001b[0;32m-> 2197\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m   2198\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt load tokenizer for \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. If you were trying to load it from \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2199\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/models\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, make sure you don\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt have a local directory with the same name. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2200\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOtherwise, make sure \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is the correct path to a directory \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2201\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontaining all relevant files for a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m tokenizer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2202\u001b[0m     )\n\u001b[1;32m   2204\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file_id, file_path \u001b[38;5;129;01min\u001b[39;00m vocab_files\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   2205\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m file_id \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m resolved_vocab_files:\n",
      "\u001b[0;31mOSError\u001b[0m: Can't load tokenizer for '/data1/malto/unlearning_llm/models/semeval25-unlearning-model-1B-model'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/data1/malto/unlearning_llm/models/semeval25-unlearning-model-1B-model' is the correct path to a directory containing all relevant files for a GPTNeoXTokenizerFast tokenizer."
     ]
    }
   ],
   "source": [
    "# At the start of your script, test this:\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "test_path = \"/data1/malto/unlearning_llm/models/semeval25-unlearning-model-1B-model\"\n",
    "print(\"Testing direct tokenizer load from:\", test_path)\n",
    "test_tokenizer = AutoTokenizer.from_pretrained(test_path, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from /data1/malto/unlearning_llm/models/semeval25-unlearning-model-1B-model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  8.88it/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "path = \"/data1/malto/unlearning_llm/\"\n",
    "\n",
    "## Fetch and load model:\n",
    "model_path = path + 'models/semeval25-unlearning-model-1B-model'\n",
    "print(f\"Loading model from {model_path}\")\n",
    "#snapshot_download(repo_id='llmunlearningsemeval2025organization/olmo-finetuned-semeval25-unlearning', token=hf_token, local_dir=model_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
