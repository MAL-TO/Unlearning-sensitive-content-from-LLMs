{"forget-set": {"overall-regurgitation-score": 0.0525332656098064, "overall-knowledge-score": 0.0, "Task1": {"regurgitation-score": 0.059620184714256765, "knowledge-score": 0.0}, "Task2": {"regurgitation-score": 0.0037267080745341614, "knowledge-score": 0.0}, "Task3": {"regurgitation-score": 0.08054693516287859, "knowledge-score": 0.0}}, "retain-set": {"overall-regurgitation-score": 0.04161796301212671, "overall-knowledge-score": 0.0, "Task1": {"regurgitation-score": 0.057823178480021525, "knowledge-score": 0.0}, "Task2": {"regurgitation-score": 0.004984126984126984, "knowledge-score": 0.0}, "Task3": {"regurgitation-score": 0.05454512741933845, "knowledge-score": 0.0}}, "mia_loss_acc": 0.5707111111111112, "mmlu_average": 0.22924084888192564, "aggregated-terms": [0.9403798152857432, 1.0, 0.9962732919254659, 1.0, 0.9194530648371214, 1.0, 0.057823178480021525, 0.0, 0.004984126984126984, 0.0, 0.05454512741933845, 0.0], "aggregate-score": 0.36260620888656775, "harmonic-mean-task-aggregate": 0, "mia_final_score": 0.8585777777777777}